<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    

    <title>
      hadoop单机模式安装.bak | Vickkyy 
    </title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    
      <meta name="author" content="Vickkyy">
    
    

    <meta name="description" content="hadoop单机模式安装第一章 前提软件安装jdk1 查看jdk安装目录echo $JAVA_HOME (以jdk 1.8.0_71为例)以 ‘/home/lvrenjie-xy/jdk1.8.0_71’ 为例 hadoop1 下载地址 http://hadoop.apache.org/releases.html2  Download 官网2.5以后的版本默认提供64位版本，在”Tarball”中">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop单机模式安装.bak | Vickkyy">
<meta property="og:url" content="http://yoursite.com/2017/09/30/hadoop单机模式安装_backup/index.html">
<meta property="og:site_name" content="Vickkyy">
<meta property="og:description" content="hadoop单机模式安装第一章 前提软件安装jdk1 查看jdk安装目录echo $JAVA_HOME (以jdk 1.8.0_71为例)以 ‘/home/lvrenjie-xy/jdk1.8.0_71’ 为例 hadoop1 下载地址 http://hadoop.apache.org/releases.html2  Download 官网2.5以后的版本默认提供64位版本，在”Tarball”中">
<meta property="og:locale" content="English">
<meta property="og:updated_time" content="2018-07-06T09:52:12.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="hadoop单机模式安装.bak | Vickkyy">
<meta name="twitter:description" content="hadoop单机模式安装第一章 前提软件安装jdk1 查看jdk安装目录echo $JAVA_HOME (以jdk 1.8.0_71为例)以 ‘/home/lvrenjie-xy/jdk1.8.0_71’ 为例 hadoop1 下载地址 http://hadoop.apache.org/releases.html2  Download 官网2.5以后的版本默认提供64位版本，在”Tarball”中">
    
    
    
      <link rel="icon" type="image/x-icon" href="/favicon.png">
    
    <link rel="stylesheet" href="/css/uno.css">
    <link rel="stylesheet" href="/css/highlight.css">
    <link rel="stylesheet" href="/css/archive.css">
    <link rel="stylesheet" href="/css/china-social-icon.css">

</head>
<body>

    <span class="mobile btn-mobile-menu">
        <i class="icon icon-list btn-mobile-menu__icon"></i>
        <i class="icon icon-x-circle btn-mobile-close__icon hidden"></i>
    </span>

    

<header class="panel-cover panel-cover--collapsed">


  <div class="panel-main">

  
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        

        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage">Vickkyy</a></h1>
        <hr class="panel-cover__divider" />

        

        <div class="navigation-wrapper">

          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">

              
                
                <li class="navigation__item"><a href="/#blog" title="" class="blog-button">首页</a></li>
              
                
                <li class="navigation__item"><a href="/about" title="" class="">关于</a></li>
              
                
                <li class="navigation__item"><a href="/archive" title="" class="">归档</a></li>
              

            </ul>
          </nav>

          <!-- ----------------------------
To add a new social icon simply duplicate one of the list items from below
and change the class in the <i> tag to match the desired social network
and then add your link to the <a>. Here is a full list of social network
classes that you can use:

    icon-social-500px
    icon-social-behance
    icon-social-delicious
    icon-social-designer-news
    icon-social-deviant-art
    icon-social-digg
    icon-social-dribbble
    icon-social-facebook
    icon-social-flickr
    icon-social-forrst
    icon-social-foursquare
    icon-social-github
    icon-social-google-plus
    icon-social-hi5
    icon-social-instagram
    icon-social-lastfm
    icon-social-linkedin
    icon-social-medium
    icon-social-myspace
    icon-social-path
    icon-social-pinterest
    icon-social-rdio
    icon-social-reddit
    icon-social-skype
    icon-social-spotify
    icon-social-stack-overflow
    icon-social-steam
    icon-social-stumbleupon
    icon-social-treehouse
    icon-social-tumblr
    icon-social-twitter
    icon-social-vimeo
    icon-social-xbox
    icon-social-yelp
    icon-social-youtube
    icon-social-zerply
    icon-mail

-------------------------------->

<!-- add social info here -->



<nav class="cover-navigation navigation--social">
  <ul class="navigation">

    
      <!-- Github -->
      <li class="navigation__item">
        <a href="https://github.com/vickkyy" title="Huno on GitHub">
          <i class='icon icon-social-github'></i>
          <span class="label">GitHub</span>
        </a>
      </li>
    

    <!-- China social icon -->
    <!--
    
      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-douban'></i>
          <span class="label">Douban</span>
        </a>
      </li>

      <li class="navigation__item">
        <a href="" title="">
          <i class='icon cs-icon-weibo'></i>
          <span class="label">Weibo</span>
        </a>
      </li>

    -->



  </ul>
</nav>



        </div>

      </div>

    </div>

    <div class="panel-cover--overlay"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner entry">
            

<article class="post-container post-container--single">

  <header class="post-header">
    
    <h1 class="post-title">hadoop单机模式安装.bak</h1>

    

    <div class="post-meta">
      <time datetime="2017-09-30" class="post-meta__date date">2017-09-30</time> 

      <span class="post-meta__tags tags">

          

          
             &#8226; 标签:
            <font class="tags">
              <a class="tags-link" href="/tags/机器学习/">机器学习</a>
            </font>
          

      </span>
    </div>
    
    

  </header>

  <section id="post-content" class="article-content post">
    <h2 id="hadoop单机模式安装"><a href="#hadoop单机模式安装" class="headerlink" title="hadoop单机模式安装"></a>hadoop单机模式安装</h2><h3 id="第一章-前提软件安装"><a href="#第一章-前提软件安装" class="headerlink" title="第一章 前提软件安装"></a>第一章 前提软件安装</h3><h4 id="jdk"><a href="#jdk" class="headerlink" title="jdk"></a>jdk</h4><p>1 查看jdk安装目录<br><code>echo $JAVA_HOME</code> (以jdk 1.8.0_71为例)<br>以 ‘/home/lvrenjie-xy/jdk1.8.0_71’ 为例</p>
<h4 id="hadoop"><a href="#hadoop" class="headerlink" title="hadoop"></a>hadoop</h4><p>1 下载地址 <a href="http://hadoop.apache.org/releases.html" target="_blank" rel="noopener">http://hadoop.apache.org/releases.html</a><br>2  Download 官网2.5以后的版本默认提供64位版本，在”Tarball”中选择对应版本的”binary”下载<br>3 安装hadoop (以hadoop-2.8.1为例)<br>    1) 新建文件夹 /opt/soft<br>    2) <code>tar -zxvf hadoop-2.8.1.tar.gz -C /opt/soft</code><br>    3) 查看hadoop是32or64位<br>    <code>cd /opt/soft/hadoop-2.8.1/lib/native</code><br>    <code>file libhadoop.so.1.0.0</code><br>4 配置<code>/etc/hosts</code><br>    本机ip地址 singlenode</p>
<hr>
<h3 id="第二章-配置启动Hadoop"><a href="#第二章-配置启动Hadoop" class="headerlink" title="第二章 配置启动Hadoop"></a>第二章 配置启动Hadoop</h3><p>1 修改<code>hadoop2.8.1/etc/hadoop/hadoop-env.sh</code>指定<code>JAVA_HOME</code><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The java implementation to use.</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/soft/jdk1.8.0_71</span><br></pre></td></tr></table></figure></p>
<p>2 修改hdfs的配置文件<br>修改<code>hadoop2.8.1/etc/hadoop/core-site.xml</code>如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定HDFS(namenode的通信地址) --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://singlenode:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop运行时产生文件的存储路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/soft/hadoop-2.8.1/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">``` </span><br><span class="line">这里fs.defaultFS的value最好写本机的静态IP地址即本机名，再配置hosts。</span><br><span class="line"></span><br><span class="line">修改hadoop2.8.1/etc/hadoop/hdfs-site.xml如下：</span><br><span class="line">```xml</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 设置hdfs副本数量 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>3 配置ssh免密登录<br>配置前：<br><code>ssh localhost</code><br>会提示请输入本机登录密码</p>
<p>配置方法：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t dsa -P <span class="string">''</span> -f ~/.ssh/id_dsa</span><br><span class="line">cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">chmod 0600 ~/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></p>
<p>配置后可免密登录</p>
<p>4 hdfs启动与停止<br>第一次启动先格式化:<br>在<code>/opt/soft/hadoop2.8.1</code>目录下执行<br><code>./bin/hdfs namenode -format</code></p>
<blockquote>
<p>备注此处有个坑，注意hostname与hosts中ip映射一致。<br>如<code>/etc/hosts</code>中配置为<code>127.0.0.1 localhost</code>, 则/etc/hostname中内容应修改为<code>localhost</code></p>
</blockquote>
<p>启动hdfs<br><code>./sbin/start-dfs.sh</code></p>
<p>测试用浏览器访问：(50070端口)<br><code>firewall-cmd --zone=public --add-port=50070/tcp --permanent</code><br><code>firewall-cmd --reload</code></p>
<blockquote>
<p>备注：如果没有安装firewall则需先安装 (apt-get install firewall)</p>
</blockquote>
<p>在浏览器中打开 <code>http://192.168.136.128:50070</code></p>
<p>停止hdfs<br><code>sbin/stop-dfs.sh</code></p>
<p>5 常用操作<br>HDFS shell</p>
<p>查看帮助<br><code>hadoop fs -help &lt;cmd&gt;</code></p>
<p>上传<br><code>hadoop fs -put &lt;linux文件&gt; &lt;hdfs上的路径&gt;</code></p>
<p>查看文件内容<br><code>hadoop fs -cat &lt;hdfs上的路径&gt;</code></p>
<p>查看文件列表<br><code>hadoop fs -ls /</code></p>
<p>下载文件<br><code>hadoop fs -get &lt;hdfs上的路径&gt; &lt;linux上文件&gt;</code></p>
<hr>
<h3 id="第三章-上传文件测试"><a href="#第三章-上传文件测试" class="headerlink" title="第三章 上传文件测试"></a>第三章 上传文件测试</h3><p>创建一个words.txt文件并上传</p>
<p><code>vim words.txt</code></p>
<p>内容如下：<br>Hello Monday<br>Hello Today<br>Hello Tomorrow<br>Hello Yesterday</p>
<p>将words.txt上传到hdfs的根目录<br><code>bin/hadoop fs -put words.txt /</code></p>
<p>然后通过浏览器访问：<code>http://192.168.136.128:50070/</code></p>
<hr>
<h3 id="第四章-配合启动YARN"><a href="#第四章-配合启动YARN" class="headerlink" title="第四章 配合启动YARN"></a>第四章 配合启动YARN</h3><p>MapReduce是运行在YARN上，而YARN是运行在HDFS上。</p>
<ol>
<li><p>配置 <code>etc/hadoop/mapred-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 通知框架MR使用YARN --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>配置 <code>etc/hadoop/yarn-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- reducer取数据的方法是mapreduce_shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>YARN的启动与停止<br>启动<br><code>./sbin/start-yarn.sh</code></p>
</li>
</ol>
<p>测试用例浏览器访问(端口8088)：</p>
<p>停止<br><code>sbin/stop-yarn.sh</code></p>
<p>现在hdfs和yarn都已正常运行，开始运行一个WordCount的MP程序来测试单机模式集群是否能正常工作。</p>
<hr>
<h3 id="第五章-运行一个测试的MP程序"><a href="#第五章-运行一个测试的MP程序" class="headerlink" title="第五章 运行一个测试的MP程序"></a>第五章 运行一个测试的MP程序</h3><p>Mapreduce将会在YARN上运行，结果存在HDFS上：<br><code>./bin/hadoop jar /opt/soft/hadoop-2.8.1/share/hadoop/mapreduce/hadoop-mapreduce-example-2.7.2.jar wordcount</code><br>用hadoop执行一个叫hadoop-mapreduce-examples.jar的wordcount方法，其中输入参数为hdfs上根目录的words.txt文件，而输出路径为hdfs根目录下的out目录，查看运行过程。</p>
<p>通过浏览器可以访问和下载查看结果。</p>
<hr>
<h2 id="Spark-安装"><a href="#Spark-安装" class="headerlink" title="Spark  安装"></a>Spark  安装</h2><h3 id="第一章-前提软件安装-1"><a href="#第一章-前提软件安装-1" class="headerlink" title="第一章 前提软件安装"></a>第一章 前提软件安装</h3><p>Scala</p>
<ol>
<li><p>下载<br><a href="http://www.scala-lang.org/" target="_blank" rel="noopener">http://www.scala-lang.org/</a></p>
</li>
<li><p>解压缩<br>tar -zxvf scala-2.12.3.tgz -C /opt/soft </p>
</li>
<li><p>进入 <code>sudo vim /etc/profile</code> 在下面添加路径：<br><code>export PATH=&quot;PATH:/opt/soft/scala-2.12.3/bin</code></p>
</li>
<li><p>使profile生效<br>source /etc/profile</p>
</li>
<li><p>在命令行中输入scala测试</p>
</li>
</ol>
<h3 id="第二章-安装Spark"><a href="#第二章-安装Spark" class="headerlink" title="第二章 安装Spark"></a>第二章 安装Spark</h3><ol>
<li><p>下载<br><a href="http://spark.apache.org/downloads.html" target="_blank" rel="noopener">http://spark.apache.org/downloads.html</a></p>
</li>
<li><p>解压缩<br>tar -zxvf spark-2.2.0-bin-hadoop2.7.tgz -C /opt/soft</p>
</li>
<li><p>进入<code>sudo vim /etc/profile</code> 在下面添加路径：<br><code>SPARK_HOME=/opt/soft/spark-2.2.0-bin-hadoop2.7</code><br>PATH=$PATH:${SPARK_HOME}/bin </p>
</li>
<li><p>测试<br>1) 在命令行中输入：spark-shell<br>2) 进入bin目录，输入./run-example SparkPi 10 (迭代计算)计算π的值</p>
</li>
</ol>
<h3 id="第三章-Wordcount示例"><a href="#第三章-Wordcount示例" class="headerlink" title="第三章 Wordcount示例"></a>第三章 Wordcount示例</h3><ul>
<li><p>列表内容<br>在命令行输入：spark-shell开启spark(scala)</p>
</li>
<li><p>把输入文件加载进RDD<br>val textFile = sc.textFile(“file_path”)<br>d</p>
</li>
<li><p>MapReduce操作，以work为key, 1为value:<br>val wordCounts = textFile.flatMap(line =&gt; line.split(“”)).map(word =&gt; (word,1)).reduceByKey((a,b) =&gt; a + b)</p>
</li>
<li><p>查看每个单词出现的次数<br>wordCounts.collect()</p>
</li>
</ul>
<hr>
<h2 id="Hbase-安装（单机环境搭建）"><a href="#Hbase-安装（单机环境搭建）" class="headerlink" title="Hbase 安装（单机环境搭建）"></a>Hbase 安装（单机环境搭建）</h2><h3 id="第一章-下载"><a href="#第一章-下载" class="headerlink" title="第一章 下载"></a>第一章 下载</h3><p>使用稳定版，本文使用的版本是Hbase-1.2.6<br><a href="http://www.apache.org/dyn/closer.cgi/hbase/" target="_blank" rel="noopener">http://www.apache.org/dyn/closer.cgi/hbase/</a></p>
<h3 id="第二章-安装"><a href="#第二章-安装" class="headerlink" title="第二章 安装"></a>第二章 安装</h3><ol>
<li><p>解压<br>tar -zxvf /home/lvrenjie/下载/hbase-1.2.6-bin.tar.gz -C /opt/soft</p>
</li>
<li><p>在/opt/soft/hbase-1.2.6/conf目录下修改hbase-env.sh<br>取消配置JDK的注释并做如下修改 (jdk的安装路径)<br>export JAVA_HOME=/home/lvrenjie/jdk1.8.0_71   (本文环境jdk安装路径)</p>
</li>
<li><p>修改hbase-site.xml (/opt/soft/hbase-1.2.6/conf目录下)</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 单机启动，只设定Hbase写入的本地路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- hbase 1.0 以后的版本，需手动配置端口 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.master.info.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>60010<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="第三章-测试"><a href="#第三章-测试" class="headerlink" title="第三章 测试"></a>第三章 测试</h3><ol>
<li><p>启动Hbase<br>在/opt/soft/hbase-1.2.6目录下输入./bin/start-hbase.sh</p>
</li>
<li><p>使用shell来连接hbase<br>在/opt/soft/hbase-1.2.6目录下输入./bin/hbase shell</p>
</li>
<li><p>建表操作<br>create ‘table1’,’col1’<br>list<br>put ‘table1’,’row1’,’col1:a’,’value1’<br>put ‘table1’,’row2’,’col1:b’,’value2’</p>
</li>
<li><p>使用scan查看表所有数据<br>scan ‘table1’</p>
</li>
<li><p>使用get查看单行数据<br>get ‘table1’,’row1’</p>
</li>
<li><p>使用disable和drop删除表<br>disable ‘table1’<br>drop ‘table1’</p>
</li>
<li><p>停止hbase<br>在/opt/soft/hbase-1.2.6目录下输入./bin/stop-hbase.sh</p>
</li>
<li><p>启动Hbase Rest服务<br>在/opt/soft/hbase-1.2.6目录下输入./bin/hbase rest start</p>
</li>
</ol>
<p>测试：<a href="http://localhost:8080" target="_blank" rel="noopener">http://localhost:8080</a></p>
<h3 id="第四章-通过浏览器查看Hbase信息"><a href="#第四章-通过浏览器查看Hbase信息" class="headerlink" title="第四章 通过浏览器查看Hbase信息"></a>第四章 通过浏览器查看Hbase信息</h3><p>访问地址：<a href="http://localhost:60010" target="_blank" rel="noopener">http://localhost:60010</a></p>
<blockquote>
<p>备注：如果60010端口不能访问，原因是hbase1.0版本以后，需要在hbase-site.xml文件中手动配置60010端口</p>
</blockquote>
<h3 id="第五章-可能遇到的问题"><a href="#第五章-可能遇到的问题" class="headerlink" title="第五章 可能遇到的问题"></a>第五章 可能遇到的问题</h3><p>hbase(main):001:0&gt;create ‘test’,’cf’</p>
<p>ERROR:org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException:<br>org.apache.hadoop.hbase.NotAllMetaRegionsOnlineException:Timed out(10000ms)</p>
<p>解决方法：<br>修改/etc/hosts. 把ubuntu对应的127.0.0.1修改为本机的IP.</p>
<hr>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><ol>
<li><p>下载<br><code>http://download.redis.io/releases/redis-3.2.11.tar.gz</code></p>
</li>
<li><p>解压<br><code>tar -zxvf /home/lvrenjie/下载/redis-3.2.11.tar.gz -C /opt/soft</code></p>
</li>
<li><p>编译<br>进入到redis安装目录下，<code>make</code></p>
</li>
<li><p>启动redis服务<br>进入到redis安装目录src下，执行<code>./redis-server</code></p>
</li>
</ol>
<blockquote>
<p>备注：这种方式启动redis使用的是默认配置。也可以通过启动参数告诉redis使用指定配置文件使用下面命令启动。<br><code>./redis-server redis.conf</code></p>
</blockquote>
<hr>
<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><ol>
<li><p>下载<br><code>http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz</code></p>
</li>
<li><p>解压<br>tar -zxvf /home/lvrenjie/下载/zookeeper-3.4.6.tar.gz -C /opt/soft </p>
</li>
<li><p>修改配置<br>进入zookeeper目录下的conf目录，复制zoo_sample.cfg为zoo.cfg，并将内容修改如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000  </span><br><span class="line">dataDir=/opt/zookeeper-3.4.6/data  </span><br><span class="line">clientPort=2181</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>备注：<br>tickTime：Zookeeper 服务器之间或客户端与服务器之间心跳的时间间隔。<br>dataDir：Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。<br>clientPort：Zookeeper 服务器监听端口，用来接受客户端的访问请求。</p>
</blockquote>
<ol start="4">
<li><p>启动zookeeper服务了<br>进入Zookeeper/bin目录，运行下面的命令来启动Zookeeper服务</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ ./zkServer.sh start  </span><br><span class="line">JMX enabled by default  </span><br><span class="line">Using config: /opt/zookeeper/bin/../conf/zoo.cfg  </span><br><span class="line">Starting zookeeper ... STARTED </span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">启动后查看服务状态</span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">$ ./zkServer.sh status  </span><br><span class="line">JMX enabled by default  </span><br><span class="line">Using config: /opt/zookeeper/bin/../conf/zoo.cfg  </span><br><span class="line">Mode: standalone</span><br></pre></td></tr></table></figure>
</li>
<li><p>在Zookeeper服务器启动以后，就可以使用Zookeeper的客户端来连接并测试了。<br><code>$ ./zkCli.sh</code><br>或<br><code>$ ./zkCli.sh -server 127.0.0.1:2181</code></p>
</li>
</ol>
<h2 id="KafKa"><a href="#KafKa" class="headerlink" title="KafKa"></a>KafKa</h2><ol>
<li><p>下载<br><code>http://www-us.apache.org/dist/kafka/0.11.0.1/kafka_2.12-0.11.0.1.tgz</code></p>
</li>
<li><p>解压<br><code>tar -zvxf /home/lvrenjie/下载/kafka_2.12-0.11.0.1.tgz -C /opt/soft</code></p>
</li>
<li><p>部署<br>修改/etc/profile文件<br><code>export KAFKA_HOME=/opt/soft/kafka_2.12-0.11.0.0</code><br><code>export PATH=$JAVA_HOME/bin:$ZOOKEEPER_HOME/bin:$MAVEN_HOME/bin:$STORM_HOME/bin:$KAFKA_HOME/bin:$PATH</code></p>
</li>
<li><p>运行</p>
<p> 1.)启动服务：Kafka用到了Zookeeper，所有首先启动Zookper，下面简单的启用一个单实例的Zookkeeper服务。<br> <code>zookeeper-server-start.sh config/zookeeper.properties &amp;</code><br> 2.)启动Kafka:<br> <code>kafka-server-start.sh config/server.properties &amp;</code></p>
</li>
<li><p>操作<br> 1.)创建topic<br> 创建一个”test” topic，它只有一个分区，一个副本:<br> <code>kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test</code><br> 通过list命令查看创建的topic:<br> <code>kafka-topics.sh --list --zookeeper localhost:2181</code></p>
<p> 2.)删除一个topic<br> <code>bin/kafka-topics.sh  --zookeeper localhost:2181 --delete --topic test</code></p>
</li>
</ol>
<hr>
<h2 id="Storm"><a href="#Storm" class="headerlink" title="Storm"></a>Storm</h2><p>１．下载<br><code>wget http://www-eu.apache.org/dist/storm/apache-storm-1.1.0/apache-storm-1.1.0.tar.gz</code>
　　</p>
<ol start="2">
<li>解压<br><code>tar -zvxf /home/lvrenjie/下载/apache-storm-1.1.1/ -C /opt/soft</code></li>
</ol>
<p>3．部署<br>在/etc/profile最后添加<br><code>export STORM_HOME=/opt/soft/apache-storm-1.1.1</code></p>
<p><code>export PATH=$JAVA_HOME/bin:$ZOOKEEPER_HOME/bin:$MAVEN_HOME/bin:$STORM_HOME/bin:$KAFKA_HOME/bin:$PATH</code></p>
<p>运行source命令使立即生效。</p>
<ol start="4">
<li><p>配置<br>进入conf目录，修改storm.yaml文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> storm.zookeeper.servers:</span><br><span class="line">     - &quot;127.0.0.1&quot;</span><br><span class="line">#     - &quot;server2&quot;</span><br><span class="line"># </span><br><span class="line"># nimbus.seeds: [&quot;host1&quot;, &quot;host2&quot;, &quot;host3&quot;]</span><br><span class="line"> nimbus.host: &quot;127.0.0.1&quot;</span><br><span class="line"> storm.zookeeper.port: 2181</span><br><span class="line"> storm.local.dir: &quot;/home/david/Storm/apache-storm-1.1.0&quot;</span><br><span class="line"> supervisor.slots.ports:</span><br><span class="line">  - 6700</span><br><span class="line">  - 6701</span><br><span class="line">  - 6702</span><br><span class="line">  - 6703</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Storm numbus</span><br><span class="line">Storm supervisor</span><br><span class="line">Storm ui</span><br></pre></td></tr></table></figure></li>
</ol>

  </section>

  <section class="post-comments">

    <!-- 将评论系统（例如Disqus、多说、友言、畅言等）提供的代码片段粘贴在这里 -->
    
</section>


</article>


            <footer class="footer">
    <span class="footer__copyright">&copy; 2015-2017. | 由<a href="https://hexo.io/">Hexo</a> | 主题<a href="https://github.com/someus/huno">Huno</a></span><span id="busuanzi_container_site_uv">本站访问数<span id="busuanzi_value_site_uv"></span>人次</span>
    
</footer>

        </div>
    </div>

    <!-- js files -->
    <script src="/js/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <script src="/js/scale.fix.js"></script>
    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    

    

    <script type="text/javascript" src="http://cdn.bootcss.com/mathjax/2.7.1/MathJax.js"></script>
    <script type="text/javascript"> 
        $(document).ready(function(){
            MathJax.Hub.Config({ 
                tex2jax: {inlineMath: [['[latex]','[/latex]'], ['\\(','\\)']]} 
            });
        });
    </script>


    

    <script src="/js/awesome-toc.min.js"></script>
    <script>
        $(document).ready(function(){
            $.awesome_toc({
                overlay: true,
                contentId: "post-content",
            });
        });
    </script>


    
    
    <!--kill ie6 -->
<!--[if IE 6]>
  <script src="//letskillie6.googlecode.com/svn/trunk/2/zh_CN.js"></script>
<![endif]-->

</body>
</html>
